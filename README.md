# Referee-Mediated Discourse: Reproducible Experimental Protocol

Complete implementation of the multi-agent debate framework with real-time hallucination detection and correction as described in "Breaking the Data Wall: High-Fidelity Knowledge Synthesis and Self-Evolving AI via Referee-Mediated Discourse".

## ğŸ¯ Overview

This implementation provides a **fully reproducible** experimental protocol for:

- Multi-agent adversarial debates
- Real-time hallucination detection via independent referee
- Turn-by-turn error correction
- Comprehensive logging and evaluation
- Standardized metrics calculation

## ğŸ“‹ Prerequisites

- Python 3.10 or higher
- API keys for:
  - Anthropic (Claude)
  - OpenAI (GPT-4)
  - Google (Gemini)

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone or download this repository
git clone <repository-url>
cd referee-mediated-discourse

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure API Keys

```bash
# Copy the example environment file
cp .env.example .env

# Edit .env and add your API keys
# ANTHROPIC_API_KEY=sk-ant-...
# OPENAI_API_KEY=sk-...
# GOOGLE_API_KEY=...
```

Or set environment variables directly:

```bash
export ANTHROPIC_API_KEY="your-key-here"
export OPENAI_API_KEY="your-key-here"
export GOOGLE_API_KEY="your-key-here"
```

### 3. Run Experiments

**Nuclear Energy Debate:**
```bash
python referee_mediated_discourse.py --experiment nuclear_energy --seed 42
```

**Good vs Evil Philosophical Debate:**
```bash
python referee_mediated_discourse.py --experiment good_vs_evil --seed 42
```

## ğŸ“Š Output Structure

Each experiment creates a timestamped output directory:

```
outputs/
â””â”€â”€ nuclear_energy_2025-01-29T10-30-45/
    â”œâ”€â”€ config.json                      # Complete experiment configuration
    â”œâ”€â”€ full_transcript.json             # Every turn with metadata
    â”œâ”€â”€ hallucination_annotations.json   # Detected hallucinations
    â”œâ”€â”€ metrics.json                     # Quantitative results
    â””â”€â”€ REPORT.md                        # Human-readable summary
```

### config.json
Contains all experimental parameters for exact reproduction:
- Agent configurations (model, temperature, prompts)
- Debate parameters (max turns, deadlock threshold)
- Random seed
- Timestamps

### full_transcript.json
Complete debate log including:
- Turn-by-turn content
- Agent metadata (model, role, persona)
- Timing information (latency per turn)
- Token usage

### hallucination_annotations.json
Referee's evaluations:
- Claim identification
- Hallucination classification (factual_error, unverifiable, misleading, correct)
- Evidence sources
- Severity ratings

### metrics.json
Quantitative results:
- Total turns
- Hallucination rate
- Correction rate
- Error type breakdown

## ğŸ”¬ Experimental Design

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent A    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Agent B    â”‚
â”‚  (Claude)   â”‚         â”‚  (GPT-4)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â”‚
       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
       â””â”€â”€â”€â–ºâ”‚  Referee    â”‚â—„â”€â”€â”˜
            â”‚  (Gemini)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
            Fact-checking
            via Web Search
```

### Process Flow

1. **Agent A** makes opening statement
2. **Referee** fact-checks Agent A's claims
3. **Agent B** responds with counter-argument
4. **Referee** fact-checks Agent B's claims
5. Repeat until max turns or deadlock detected
6. **Evaluation** extracts hallucination metrics

### Key Features

- **Turn-by-turn isolation**: Each claim is verified before the next turn
- **Real-time grounding**: Referee uses web search for fact verification
- **Heterogeneous models**: Different AI providers prevent model-specific bias
- **Deadlock detection**: Identifies circular reasoning automatically
- **Complete logging**: Every interaction is recorded for analysis

## ğŸ“ˆ Metrics Calculated

| Metric | Description |
|--------|-------------|
| Hallucination Rate | % of turns containing factual errors |
| Correction Rate | % of hallucinations caught by referee |
| Factual Errors | Count of provably false claims |
| Unverifiable Claims | Count of claims without sources |
| Misleading Claims | Count of technically true but deceptive statements |

## ğŸ”„ Reproducibility Guarantees

This implementation ensures reproducibility through:

1. **Fixed random seeds**: Control stochastic behavior
2. **Versioned dependencies**: requirements.txt pins exact versions
3. **Complete configuration logging**: Every parameter is recorded
4. **Timestamped outputs**: No data overwrites
5. **Model version specification**: Exact model strings (e.g., "gpt-4o", "claude-3-5-sonnet-20241022")

### Reproducing Published Results

To reproduce a specific experiment:

```bash
# Use the same seed and configuration
python referee_mediated_discourse.py \
    --experiment nuclear_energy \
    --seed 42
```

Compare your `metrics.json` with published results.

## ğŸ› ï¸ Customization

### Adding New Experiments

1. Add system prompts to `SYSTEM_PROMPTS` dictionary
2. Create new `ExperimentConfig` in `_get_experiment_config()`
3. Add initial prompt in `run_debate()` method

Example:

```python
# In SYSTEM_PROMPTS
SYSTEM_PROMPTS["debater_climate_skeptic"] = """
You are a climate change skeptic presenting evidence-based arguments...
"""

# In _get_experiment_config()
configs["climate_debate"] = ExperimentConfig(
    experiment_id=f"climate_debate_{self.timestamp}",
    topic="Climate Change: Urgency and Solutions",
    # ... rest of configuration
)
```

### Modifying Agent Models

Edit the `AgentConfig` objects:

```python
agent_a=AgentConfig(
    name="Your Agent Name",
    role=AgentRole.DEBATER_A,
    model="claude-3-opus-20240229",  # Different Claude model
    temperature=0.5,                  # Lower temperature
    max_tokens=2000,                  # More tokens
    # ...
)
```

### Adjusting Debate Parameters

```python
ExperimentConfig(
    max_turns=20,              # Longer debate
    deadlock_threshold=5,      # More tolerant of repetition
    # ...
)
```

## ğŸ› Troubleshooting

### API Key Errors

```
ValueError: ANTHROPIC_API_KEY environment variable not set
```

**Solution**: Ensure environment variables are set:
```bash
export ANTHROPIC_API_KEY="sk-ant-..."
```

### Rate Limiting

If you hit API rate limits:
1. Reduce `max_turns` in experiment config
2. Add delays between turns
3. Use lower-tier models for testing

### Import Errors

```
ModuleNotFoundError: No module named 'anthropic'
```

**Solution**: Install dependencies:
```bash
pip install -r requirements.txt
```

## ğŸ“Š Example Results

**Nuclear Energy Debate (10 turns, seed 42)**

```json
{
  "total_turns": 20,
  "debater_turns": 10,
  "referee_interventions": 10,
  "hallucination_rate": 0.02,
  "correction_rate": 0.98,
  "factual_errors": 0,
  "unverifiable_claims": 2,
  "misleading_claims": 0
}
```

## ğŸ” Security Notes

- **Never commit API keys** to version control
- Use `.gitignore` to exclude `.env` files
- Rotate keys regularly
- Monitor API usage for unexpected costs

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@article{referee_mediated_discourse_2025,
  title={Breaking the Data Wall: High-Fidelity Knowledge Synthesis and Self-Evolving AI via Referee-Mediated Discourse},
  author={[Authors]},
  year={2025}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:

- [ ] More sophisticated hallucination detection
- [ ] Multi-referee consensus mechanisms
- [ ] Automated human intervention simulation
- [ ] Visualization dashboards
- [ ] Additional evaluation metrics

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ’¬ Support

For issues or questions:
- Open a GitHub issue
- Check existing issues for solutions
- Review the troubleshooting section

## ğŸ”— Related Work

- Multi-Agent Debate (MAD)
- Constitutional AI
- RLHF (Reinforcement Learning from Human Feedback)
- Self-Refine

## ğŸ“š Further Reading

- [Anthropic Claude Documentation](https://docs.anthropic.com)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [Google Gemini API Guide](https://ai.google.dev/docs)
